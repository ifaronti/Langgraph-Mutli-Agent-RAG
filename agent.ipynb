{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c2f764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from operator import add as add_messages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.tools import tool\n",
    "from pydantic_settings import BaseSettings\n",
    "# from file_path import file_path\n",
    "from pathlib import Path\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    GOOGLE_API_KEY:str\n",
    "\n",
    "setting = Settings()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = setting.GOOGLE_API_KEY\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\")\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32067334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = file_path(input(\"Enter or paste path of pdf file you want to load to llm's memory\"))]\n",
    "desktop = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")      # â†’ /Users/you/Desktop\n",
    "file_name = \"africa_econ.pdf\"                                      # change this\n",
    "file_path = os.path.join(desktop, file_name)\n",
    "\n",
    "try:\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(\"The path does not exist\")\n",
    "    \n",
    "    file_pages = PyPDFLoader(file_path).load()\n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58c372ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=120)\n",
    "docs = splitter.split_documents(file_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a1d27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_dir = \"./Africonomy\"\n",
    "\n",
    "if not os.path.isdir(chroma_dir):\n",
    "    os.mkdir(chroma_dir)\n",
    "\n",
    "try:\n",
    "        vector_store = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        persist_directory=chroma_dir,\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"Africonomy\"\n",
    "    )\n",
    "except Exception as e:\n",
    "      print(str(e))\n",
    "      raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db28e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", \n",
    "    search_kwargs={\"k\":80, \"score_threshold\":0.5}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "372cb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def vector_search(query:str)-> str:\n",
    "    \"\"\"Searches the vector database to and retrives documents based on recieved query.\"\"\"\n",
    "\n",
    "    docs = retriever.invoke(query)\n",
    "\n",
    "    if not docs:\n",
    "        return \"No document matches the query in the vector db\"\n",
    "    \n",
    "    response: list[str] =[]\n",
    "    \n",
    "    for i, doc in enumerate(docs):\n",
    "        response.append(f\"document {i+1}: {doc}\")\n",
    "\n",
    "    return \"\\n \".join(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d28782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [vector_search]\n",
    "llm = llm.bind_tools(tools)\n",
    "\n",
    "class AgenState(TypedDict):\n",
    "    messages:Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "tools_dict = {tool.name:tool for tool in tools}\n",
    "\n",
    "sys_prompt = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6cd37bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm(state:AgenState)-> AgenState:\n",
    "    \"\"\"Calls the llm with state messages and system prompt and returns response of the llm\"\"\"\n",
    "\n",
    "    messages = list(state['messages']) + [SystemMessage(content=sys_prompt)]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df7327b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state:AgenState)->bool:\n",
    "    \"\"\"Checks the last message for tool calls to determine if to call another tool or end the conversation.\"\"\"\n",
    "\n",
    "    last_msg = state['messages'][-1]\n",
    "\n",
    "    return hasattr(last_msg, \"tool_calls\") and len(last_msg.tool_calls) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1a2ee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def invoke_tool(state:AgenState)-> AgenState:\n",
    "#     \"\"\"Invokes the needed tool and checks that the tool name exists.\"\"\"\n",
    "\n",
    "#     tool_calls = state['messages'][-1].tool_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
